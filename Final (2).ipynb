{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get feature data from file as a matrix with a row per data instance'''\n",
    "import sys\n",
    "def getFeatureData(featureFile,n):\n",
    "    x=[]\n",
    "    dFile = open(featureFile, 'r')\n",
    "    i = 0\n",
    "    for line in dFile:\n",
    "        row = line.split()\n",
    "        rVec = [float(item) for item in row]\n",
    "        x.append(rVec)\n",
    "        print(str(int(i/n*100)) + \"%\",end = '\\r')\n",
    "        sys.stdout.flush()\n",
    "        i += 1\n",
    "    print('100%')\n",
    "    dFile.close()\n",
    "    return x\n",
    "\n",
    "'''Get label data from file as a dictionary with key as data instance index\n",
    "and value as the class index\n",
    "'''\n",
    "def getLabelData(labelFile,n):\n",
    "    lFile = open(labelFile, 'r')\n",
    "    lDict = {}\n",
    "    i = 0\n",
    "    for line in lFile:\n",
    "        row = line.split()\n",
    "        lDict[int(row[1])] = int(row[0])\n",
    "        print(str(int(i/n*100)) + \"%\",end = '\\r')\n",
    "        sys.stdout.flush()\n",
    "        i += 1\n",
    "    print('100%')\n",
    "    lFile.close()\n",
    "    return lDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled Data: \n",
      "100%\n",
      "Labels :\n",
      "100%\n"
     ]
    }
   ],
   "source": [
    "print(\"Labeled Data: \"),\n",
    "x = getFeatureData('D:\\\\moconnor\\\\My Documents\\\\M.S. Data Science\\\\Fall 2018\\\\CS675\\\\Testing\\\\traindata',8000)\n",
    "print (\"Labels :\"),\n",
    "y_dict = getLabelData('D:\\\\moconnor\\\\My Documents\\\\M.S. Data Science\\\\Fall 2018\\\\CS675\\\\Testing\\\\trainingLabels.txt',8000)\n",
    "print(\"Testing Data: \"),\n",
    "test_data = getFeatureData('D:\\\\moconnor\\\\My Documents\\\\M.S. Data Science\\\\Fall 2018\\\\CS675\\\\Testing\\\\testdata',2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into testing and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_size = .90\n",
    "rand_index = random.sample(range(len(x)),int(train_size*len(x)))\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x  = []\n",
    "test_y  = []\n",
    "for i in range(len(x)):\n",
    "    if i in rand_index:\n",
    "        train_x.append(x[i])\n",
    "        train_y.append(y_dict[i])\n",
    "    else:\n",
    "        test_x.append(x[i])\n",
    "        test_y.append(y_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "## Calculate Signal to Noise Ratio\n",
    "(Golub et al)\n",
    "\n",
    "$snr = \\left|\\frac{(m_{c1}-m_{c2})}{(\\sigma _{c1} + \\sigma_{c2})}\\right|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = []\n",
    "class_1 = []\n",
    "for i in range(len(train_x)):\n",
    "    if train_y[i] == 0:\n",
    "        class_0.append(train_x[i])\n",
    "    else:\n",
    "        class_1.append(train_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_c0 = [sum(class_0[i][j] for i in range(len(class_0)))/len(class_0) for j in range(len(train_x[0]))]\n",
    "mean_c1 = [sum(class_1[i][j] for i in range(len(class_1)))/len(class_1) for j in range(len(train_x[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_c0 = [sum([(class_0[i][j]-mean_c0[j])**2 for i in range(len(class_0))])/len(class_0) for j in range(len(class_0[0]))]\n",
    "std_c0 = [vi**(1/2) for vi in var_c0]\n",
    "var_c1 = [sum([(class_1[i][j]-mean_c1[j])**2 for i in range(len(class_1))])/len(class_1) for j in range(len(class_1[0]))]\n",
    "std_c1 = [vi**(1/2) for vi in var_c1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = [[abs((mean_c0[j]-mean_c1[j])/(std_c0[j]+std_c1[j])),j] for j in range(len(train_x[0]))]\n",
    "snr = sorted(snr, key = lambda row: row[0], reverse = True)\n",
    "top_snr = [pi[1] for pi in snr[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mutual Information\n",
    "$I_{xy}=\\sum\\limits_{y\\in Y}\\sum\\limits_{x\\in X} p(x,y)log(\\frac{p(x,y)}{p(x)p(y)})$\n",
    "\n",
    "(Cho et. al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def mi_score(u,v):\n",
    "    mi = 0\n",
    "    for ui in set(u):\n",
    "        for vi in set(v):\n",
    "            ui_vi = list(zip(u,v)).count((ui,vi))\n",
    "            if ui_vi == 0:\n",
    "                pass\n",
    "            else:\n",
    "                mi += (ui_vi/len(u))*math.log((len(u)*ui_vi)/(u.count(ui)*v.count(vi)))\n",
    "    return mi\n",
    "\n",
    "mi_array = [[j, mi_score([train_x[i][j] for i in range(len(train_x))], train_y)] for j in range(len(train_x[0]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_array = sorted(mi, key=lambda row: row[1], reverse=True)\n",
    "top_mi = [pi[0] for pi in mi_array[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Pearson Coefficient\n",
    "$r_{xy}=\\frac{\\sum\\limits_{i=1}^n(x_i-\\bar x)(y_i-\\bar y)}{\\sqrt{\\sum\\limits_{i=1}^n(xi-\\bar x)^2}\\sqrt{\\sum\\limits_{i=1}^n(y_i-\\bar y)^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, -5.8242839733508065e-08], [1, 5.117483790325117e-07], [2, 3.4378318586352323e-07], [3, 1.0699963549924643e-07], [4, 4.2321948490701064e-07], [5, 8.904297458133807e-07], [6, -2.4600473408262734e-06], [7, -8.486771070639851e-07], [8, 1.6448224825847449e-06], [9, 2.3998415257232294e-06], [10, -1.1328373913681415e-06], [11, -2.6825877141731734e-06], [12, 1.5559393928232262e-06], [13, 1.8627626859855095e-06], [14, -2.0072536058148436e-06], [15, -2.8413745206880054e-06], [16, -3.641826547396104e-07], [17, -2.3833717455826077e-06], [18, 6.543072920639188e-07], [19, -9.109384801678499e-07]]\n"
     ]
    }
   ],
   "source": [
    "def mean(u):\n",
    "    return sum(u)/len(u)\n",
    "\n",
    "def fn_a(u):\n",
    "    return (len(u)*sum([ui**2 for ui in u])-sum(u)**2)**(1/2)\n",
    "\n",
    "def pearson_coef(u,v, mu_v, fn_a_v):\n",
    "    mu_u = mean(u)\n",
    "    fn_a_u = fn_a(u)\n",
    "    return (sum([u[i]*v[i] for i in range(len(u))])-len(u)*mu_u*mu_v)/(fn_a(u)*fn_a(v))\n",
    "\n",
    "pearson_array = []\n",
    "mu_y_train = mean(train_y)\n",
    "fn_a_y_train = fn_a(train_y)\n",
    "for j in range(len(train_x[0])):\n",
    "    pearson_array.append([j, pearson_coef([train_x[i][j] for i in range(len(train_x))], train_y, mu_y_train, fn_a_y_train)])\n",
    "    print(str(int(j/len(train_x)*100)) + \"%\",end = '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson = sorted(pearson_array, key = lambda row: row[1])\n",
    "top_pearson = [pi[0] for pi in pearson[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose best features\n",
    "Find elements that are meaured as highly correlated by both standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = []\n",
    "for pi in top_mi:\n",
    "    if pi in top_snr and top_pearson:\n",
    "        common.append(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different feature subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_x_vec = []\n",
    "red_x_test_vec = []\n",
    "for n in [28,29,30,31,32]:    \n",
    "    red_x = []\n",
    "    red_x_test = []\n",
    "    for i in range(len(train_x)):\n",
    "        red_x.append([train_x[i][j] for j in common[:n]])\n",
    "    red_x_vec.append(red_x)\n",
    "    for i in range(len(test_x)):    \n",
    "        red_x_test.append([test_x[i][j] for j in common[:n]])\n",
    "    red_x_test_vec.append(red_x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy with Different Models\n",
    "For each subset of features, output accuracy for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features:  28\n",
      "\n",
      "Linear SVM\n",
      "0.67375\n",
      "Poly SVM\n",
      "0.67375\n",
      "RBF SVM\n",
      "0.655\n",
      "Number of Features:  29\n",
      "\n",
      "Linear SVM\n",
      "0.67375\n",
      "Poly SVM\n",
      "0.66125\n",
      "RBF SVM\n",
      "0.65625\n",
      "Number of Features:  30\n",
      "\n",
      "Linear SVM\n",
      "0.675\n",
      "Poly SVM\n",
      "0.67\n",
      "RBF SVM\n",
      "0.65375\n",
      "Number of Features:  31\n",
      "\n",
      "Linear SVM\n",
      "0.67625\n",
      "Poly SVM\n",
      "0.67\n",
      "RBF SVM\n",
      "0.655\n",
      "Number of Features:  32\n",
      "\n",
      "Linear SVM\n",
      "0.66875\n",
      "Poly SVM\n",
      "0.67\n",
      "RBF SVM\n",
      "0.6575\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for (red_x, red_x_test) in zip(red_x_vec,red_x_test_vec):\n",
    "    print(\"Number of Features: \", len(red_x[0]))\n",
    "    print()\n",
    "    print(\"Linear SVM\")\n",
    "    clf = svm.SVC(kernel = \"linear\", C=2.0)\n",
    "    y_hat = clf.fit(red_x,train_y).predict(red_x_test)\n",
    "    acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test))])/len(red_x_test)\n",
    "    print(acc)\n",
    "    \n",
    "    print(\"Poly SVM\")\n",
    "    clf = svm.SVC(kernel = \"poly\", degree = 2, C=2.0)\n",
    "    y_hat = clf.fit(red_x,train_y).predict(red_x_test)\n",
    "    acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test))])/len(red_x_test)\n",
    "    print(acc)\n",
    "        \n",
    "    print(\"RBF SVM\")\n",
    "    clf = svm.SVC(kernel = \"rbf\", C=2.0)\n",
    "    y_hat = clf.fit(red_x,train_y).predict(red_x_test)\n",
    "    acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test))])/len(red_x_test)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM seems to be working the best, this is consistent with the literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_common = [[train_x[i][j] for j in common]for i in range(len(train_x))]\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 15).fit(matrixTranspose(train_x_common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_clustered = []\n",
    "clusters = []\n",
    "for c in range(len(common)):\n",
    "    if kmeans.labels_[c] not in clusters:\n",
    "        clusters.append(c)\n",
    "        common_clustered.append(common[c])\n",
    "common_clustered = common_clustered[:]\n",
    "red_x_clustered = [[train_x[i][j] for j in common_clustered] for i in range(len(train_x))]\n",
    "red_x_test_clustered = [[test_x[i][j] for j in common_clustered] for i in range(len(test_x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "0.67\n",
      "Poly SVM\n",
      "0.68\n",
      "RBF SVM\n",
      "0.67875\n"
     ]
    }
   ],
   "source": [
    "y_hats = []\n",
    "print(\"Linear SVM\")\n",
    "clf = svm.SVC(kernel = \"linear\", C=2.0)\n",
    "y_hat = clf.fit(red_x_clustered,train_y).predict(red_x_test_clustered)\n",
    "y_hats.append(y_hat)\n",
    "acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test_clustered))])/len(red_x_test_clustered)\n",
    "print(acc)\n",
    "\n",
    "print(\"Poly SVM\")\n",
    "clf = svm.SVC(kernel = \"poly\", degree = 2, C=2.0)\n",
    "y_hat = clf.fit(red_x_clustered,train_y).predict(red_x_test_clustered)\n",
    "acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test_clustered))])/len(red_x_test_clustered)\n",
    "y_hats.append(y_hat)\n",
    "print(acc)\n",
    "\n",
    "print(\"RBF SVM\")\n",
    "clf = svm.SVC(kernel = \"rbf\", C=2.0)\n",
    "y_hat = clf.fit(red_x_clustered,train_y).predict(red_x_test_clustered)\n",
    "acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test_clustered))])/len(red_x_test_clustered)\n",
    "y_hats.append(y_hat)\n",
    "print(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6825\n"
     ]
    }
   ],
   "source": [
    "y_hat = []\n",
    "for i in range(len(red_x_test_clustered)):\n",
    "    if y_hats[0][i]+y_hats[1][i]+y_hats[2][i] < 1.5:\n",
    "        y_hat.append(0)\n",
    "    else:\n",
    "        y_hat.append(1)\n",
    "acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test_clustered))])/len(red_x_test_clustered)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
