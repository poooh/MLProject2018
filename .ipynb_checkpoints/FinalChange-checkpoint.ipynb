{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from time import time\n",
    "import random\n",
    "import sys\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get feature data from file as a matrix with a row per data instance'''\n",
    "def getFeatureData(featureFile,n):\n",
    "    x=[]\n",
    "    dFile = open(featureFile, 'r')\n",
    "    i = 0\n",
    "    for line in dFile:\n",
    "        row = line.split()\n",
    "        rVec = [float(item) for item in row]\n",
    "        x.append(rVec)\n",
    "        print(str(int(i/n*100)) + \"%\",end = '\\r')\n",
    "        sys.stdout.flush()\n",
    "        i += 1\n",
    "    print('100%')\n",
    "    dFile.close()\n",
    "    return x\n",
    "\n",
    "'''Get label data from file as a dictionary with key as data instance index\n",
    "and value as the class index\n",
    "'''\n",
    "def getLabelData(labelFile,n):\n",
    "    lFile = open(labelFile, 'r')\n",
    "    lDict = {}\n",
    "    i = 0\n",
    "    for line in lFile:\n",
    "        row = line.split()\n",
    "        lDict[int(row[1])] = int(row[0])\n",
    "        print(str(int(i/n*100)) + \"%\",end = '\\r')\n",
    "        sys.stdout.flush()\n",
    "        i += 1\n",
    "    print('100%')\n",
    "    lFile.close()\n",
    "    return lDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled Data: \n",
      "100%\n",
      "Labels :\n",
      "100%\n",
      "Testing Data: \n",
      "100%\n"
     ]
    }
   ],
   "source": [
    "print(\"Labeled Data: \"),\n",
    "x = getFeatureData('/home/pooja/Desktop/college-20181129T060930Z-001/college/ML-675/Project/traindata',8000)\n",
    "print (\"Labels :\"),\n",
    "y_dict = getLabelData('/home/pooja/Desktop/college-20181129T060930Z-001/college/ML-675/Project/trainingLabels.txt',8000)\n",
    "print(\"Testing Data: \"),\n",
    "test_data = getFeatureData('/home/pooja/Desktop/college-20181129T060930Z-001/college/ML-675/Project/testdata',2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into testing and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = .90\n",
    "rand_index = random.sample(range(len(x)),int(train_size*len(x)))\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x  = []\n",
    "test_y  = []\n",
    "for i in range(len(x)):\n",
    "    if i in rand_index:\n",
    "        train_x.append(x[i])\n",
    "        train_y.append(y_dict[i])\n",
    "    else:\n",
    "        test_x.append(x[i])\n",
    "        test_y.append(y_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "## Calculate Signal to Noise Ratio\n",
    "(Golub et al)\n",
    "\n",
    "$snr = \\left|\\frac{(m_{c1}-m_{c2})}{(\\sigma _{c1} + \\sigma_{c2})}\\right|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = []\n",
    "class_1 = []\n",
    "for i in range(len(train_x)):\n",
    "    if train_y[i] == 0:\n",
    "        class_0.append(train_x[i])\n",
    "    else:\n",
    "        class_1.append(train_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = len(class_0)\n",
    "# mean_c0 = [sum(dim)/l for dim in zip(*class_0)]\n",
    "# l = len(class_1)\n",
    "# mean_c1 = [sum(dim)/l for dim in zip(*class_1)]\n",
    "mean_c0 = [sum(class_0[i][j] for i in range(len(class_0)))/len(class_0) for j in range(len(train_x[0]))]\n",
    "mean_c1 = [sum(class_1[i][j] for i in range(len(class_1)))/len(class_1) for j in range(len(train_x[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# l = len(class_0)\n",
    "# std_c0 = [math.sqrt(sum((i - j) ** 2 for i, j in zip(xi, mean_c0)) / l) for xi in class_0]\n",
    "# l = len(class_1)\n",
    "# std_c1 = [math.sqrt(sum((i - j) ** 2 for i, j in zip(xi, mean_c1)) / l) for xi in class_1]\n",
    "\n",
    "var_c0 = [sum([(class_0[i][j]-mean_c0[j])**2 for i in range(len(class_0))])/len(class_0) for j in range(len(class_0[0]))]\n",
    "std_c0 = [vi**(1/2) for vi in var_c0]\n",
    "var_c1 = [sum([(class_1[i][j]-mean_c1[j])**2 for i in range(len(class_1))])/len(class_1) for j in range(len(class_1[0]))]\n",
    "std_c1 = [vi**(1/2) for vi in var_c1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snr = [(abs((m0-m1)/(s0+s1)),j) for m0, m1, s0, s1, j in zip(mean_c0, mean_c1, std_c0, std_c1, range(len(mean_c0)))]\n",
    "# tsnr = [i[1] for i in sorted(snr, key = lambda row: -row[0])[:100]]\n",
    "snr = [[abs((mean_c0[j]-mean_c1[j])/(std_c0[j]+std_c1[j])),j] for j in range(len(train_x[0]))]\n",
    "snr = sorted(snr, key = lambda row: row[0], reverse = True)\n",
    "top_snr = [pi[1] for pi in snr[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mutual Information\n",
    "$I_{xy}=\\sum\\limits_{y\\in Y}\\sum\\limits_{x\\in X} p(x,y)log(\\frac{p(x,y)}{p(x)p(y)})$\n",
    "\n",
    "(Cho et. al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mi_score(u,v):\n",
    "    mi = 0\n",
    "    for ui in set(u):\n",
    "        for vi in set(v):\n",
    "            ui_vi = list(zip(u,v)).count((ui,vi))\n",
    "            if ui_vi == 0:\n",
    "                pass\n",
    "            else:\n",
    "                mi += (ui_vi/len(u))*math.log((len(u)*ui_vi)/(u.count(ui)*v.count(vi)))\n",
    "    return mi\n",
    "\n",
    "mi_array = [[j, mi_score([train_x[i][j] for i in range(len(train_x))], train_y)] for j in range(len(train_x[0]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_array = sorted(mi_array, key=lambda row: row[1], reverse=True)\n",
    "top_mi = [pi[0] for pi in mi_array[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Pearson Coefficient\n",
    "$r_{xy}=\\frac{\\sum\\limits_{i=1}^n(x_i-\\bar x)(y_i-\\bar y)}{\\sqrt{\\sum\\limits_{i=1}^n(xi-\\bar x)^2}\\sqrt{\\sum\\limits_{i=1}^n(y_i-\\bar y)^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\r"
     ]
    }
   ],
   "source": [
    "def mean(u):\n",
    "    return sum(u)/len(u)\n",
    "\n",
    "def fn_a(u):\n",
    "    return (len(u)*sum([ui**2 for ui in u])-sum(u)**2)**(1/2)\n",
    "\n",
    "def pearson_coef(u,v, mu_v, fn_a_v):\n",
    "    mu_u = mean(u)\n",
    "    fn_a_u = fn_a(u)\n",
    "    return (sum([u[i]*v[i] for i in range(len(u))])-len(u)*mu_u*mu_v)/(fn_a(u)*fn_a(v))\n",
    "\n",
    "pearson_array = []\n",
    "mu_y_train = mean(train_y)\n",
    "fn_a_y_train = fn_a(train_y)\n",
    "for j in range(len(train_x[0])):\n",
    "    pearson_array.append([j, pearson_coef([train_x[i][j] for i in range(len(train_x))], train_y, mu_y_train, fn_a_y_train)])\n",
    "    print(str(int(j/len(train_x[0])*100)) + \"%\",end = '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson = sorted(pearson_array, key = lambda row: row[1])\n",
    "top_pearson = [pi[0] for pi in pearson[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose best features\n",
    "Find elements that are meaured as highly correlated by both standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = []\n",
    "for pi in top_mi:\n",
    "    if pi in top_snr and top_pearson:\n",
    "        common.append(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different feature subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_x_vec = []\n",
    "red_x_test_vec = []\n",
    "for n in [28,29,30,31,32]:    \n",
    "    red_x = []\n",
    "    red_x_test = []\n",
    "    for i in range(len(train_x)):\n",
    "        red_x.append([train_x[i][j] for j in common[:n]])\n",
    "    red_x_vec.append(red_x)\n",
    "    for i in range(len(test_x)):    \n",
    "        red_x_test.append([test_x[i][j] for j in common[:n]])\n",
    "    red_x_test_vec.append(red_x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy with Different Models\n",
    "For each subset of features, output accuracy for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features:  14\n",
      "\n",
      "Linear SVM\n",
      "0.59125\n",
      "Poly SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57\n",
      "RBF SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57625\n",
      "Number of Features:  14\n",
      "\n",
      "Linear SVM\n",
      "0.59125\n",
      "Poly SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57\n",
      "RBF SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57625\n",
      "Number of Features:  14\n",
      "\n",
      "Linear SVM\n",
      "0.59125\n",
      "Poly SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57\n",
      "RBF SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57625\n",
      "Number of Features:  14\n",
      "\n",
      "Linear SVM\n",
      "0.59125\n",
      "Poly SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57\n",
      "RBF SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57625\n",
      "Number of Features:  14\n",
      "\n",
      "Linear SVM\n",
      "0.59125\n",
      "Poly SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57\n",
      "RBF SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57625\n"
     ]
    }
   ],
   "source": [
    "for (red_x, red_x_test) in zip(red_x_vec,red_x_test_vec):\n",
    "    print(\"Number of Features: \", len(red_x[0]))\n",
    "    print()\n",
    "    print(\"Linear SVM\")\n",
    "    clf = svm.SVC(kernel = \"linear\", C=2.0)\n",
    "    y_hat = clf.fit(red_x,train_y).predict(red_x_test)\n",
    "    acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test))])/len(red_x_test)\n",
    "    print(acc)\n",
    "    \n",
    "    print(\"Poly SVM\")\n",
    "    clf = svm.SVC(kernel = \"poly\", degree = 2, C=2.0)\n",
    "    y_hat = clf.fit(red_x,train_y).predict(red_x_test)\n",
    "    acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test))])/len(red_x_test)\n",
    "    print(acc)\n",
    "        \n",
    "    print(\"RBF SVM\")\n",
    "    clf = svm.SVC(kernel = \"rbf\", C=2.0)\n",
    "    y_hat = clf.fit(red_x,train_y).predict(red_x_test)\n",
    "    acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test))])/len(red_x_test)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM seems to be working the best, this is consistent with the literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x_common = [[train_x[i][j] for j in common]for i in range(len(train_x))]\n",
    "kmeans = KMeans(n_clusters = 15).fit(train_x_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_clustered = []\n",
    "clusters = []\n",
    "for c in range(len(common)):\n",
    "    if kmeans.labels_[c] not in clusters:\n",
    "        clusters.append(c)\n",
    "        common_clustered.append(common[c])\n",
    "common_clustered = common_clustered[:]\n",
    "red_x_clustered = [[train_x[i][j] for j in common_clustered] for i in range(len(train_x))]\n",
    "red_x_test_clustered = [[test_x[i][j] for j in common_clustered] for i in range(len(test_x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "0.57625\n",
      "Poly SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57625\n",
      "RBF SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59\n"
     ]
    }
   ],
   "source": [
    "y_hats = []\n",
    "print(\"Linear SVM\")\n",
    "clf = svm.SVC(kernel = \"linear\", C=2.0)\n",
    "y_hat = clf.fit(red_x_clustered,train_y).predict(red_x_test_clustered)\n",
    "y_hats.append(y_hat)\n",
    "acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test_clustered))])/len(red_x_test_clustered)\n",
    "print(acc)\n",
    "\n",
    "print(\"Poly SVM\")\n",
    "clf = svm.SVC(kernel = \"poly\", degree = 2, C=2.0)\n",
    "y_hat = clf.fit(red_x_clustered,train_y).predict(red_x_test_clustered)\n",
    "acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test_clustered))])/len(red_x_test_clustered)\n",
    "y_hats.append(y_hat)\n",
    "print(acc)\n",
    "\n",
    "print(\"RBF SVM\")\n",
    "clf = svm.SVC(kernel = \"rbf\", C=2.0)\n",
    "y_hat = clf.fit(red_x_clustered,train_y).predict(red_x_test_clustered)\n",
    "acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test_clustered))])/len(red_x_test_clustered)\n",
    "y_hats.append(y_hat)\n",
    "print(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58\n"
     ]
    }
   ],
   "source": [
    "y_hat = []\n",
    "for i in range(len(red_x_test_clustered)):\n",
    "    if y_hats[0][i]+y_hats[1][i]+y_hats[2][i] < 1.5:\n",
    "        y_hat.append(0)\n",
    "    else:\n",
    "        y_hat.append(1)\n",
    "acc = sum([y_hat[i] == test_y[i] for i in range(len(red_x_test_clustered))])/len(red_x_test_clustered)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
